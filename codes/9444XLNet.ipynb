{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b4a2d8-7e82-4906-ad78-f516fd9f9a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202013b5-5e24-4b65-82af-71383bd710b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras import backend as K\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score, precision_recall_fscore_support, f1_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, XLNetModel, AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a26199-3411-45be-9227-58887b6c1dc3",
   "metadata": {},
   "source": [
    "# from Dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "401ec146-f48d-45d8-9499-70aedba5d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(os.path.abspath(\"../..\"))\n",
    "# from skimage.io import imread, imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b89795a-6429-4263-910e-311af3c83297",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4ce857-c097-45fb-8685-6ae1d16009a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_storage(logfile_path):\n",
    "    logging.basicConfig(filename=logfile_path, filemode='a', level=logging.INFO, format='%(asctime)s => %(message)s')\n",
    "    logging.info(torch.__version__)\n",
    "    logging.info(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb873d-58ca-46d4-b7ee-9d088a77174a",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18d8847-34a5-4e44-a9dd-beee1ee12173",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "num_epochs = 3\n",
    "MAX_LEN = 128\n",
    "batch_size = 10\n",
    "dataset = 'data'\n",
    "model = 'xlnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93b74a9-d8ec-44b8-8c17-439ea2ce41e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xlnet_data_128_10_2e05'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ending_path = ('%s_%s_%s_%s_%s' %(model, dataset, MAX_LEN, batch_size, str(lr).replace(\"-\", \"\")))\n",
    "ending_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4e6cc00-44ab-4db8-ba0b-0035dc6b56de",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = \"../models/\"\n",
    "if not os.path.exists(save_model_path):\n",
    "    os.mkdir(save_model_path)\n",
    "logfile_path = \"../logs/\" + ending_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7cb214-2451-4fb2-8d80-4c81625571e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_storage(logfile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff274c4e-3ce8-4f38-98d0-256aa04f4c4e",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a6b7e1-ebb1-41b1-b947-5f7bf2754233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5707 862 1441\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/train_data.csv')\n",
    "\n",
    "\n",
    "df_dev = pd.read_csv('../data/dev_data.csv')\n",
    "\n",
    "\n",
    "\n",
    "df_test = pd.read_csv('../data/test_data.csv')\n",
    "\n",
    "\n",
    "print(len(df_train), len(df_test), len(df_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a7c0bee-c4a6-44da-b5c5-e988bb5967cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_train.iterrows():\n",
    "    df_train.at[i, 'input'] = \" <cls> \" + str(row[1]) + \" <sep> \" + str(row[2]) + \" <cls> \"\n",
    "    if(i % 100000) == 0 and i:\n",
    "        print(\"Completed: %s\" %(i))\n",
    "for i, row in df_dev.iterrows():\n",
    "    df_dev.at[i, 'input'] = \" <cls> \" + str(row[1]) + \" <sep> \" + str(row[2]) + \" <cls> \"\n",
    "    if(i % 100000) == 0 and i:\n",
    "        print(\"Completed: %s\" %(i))\n",
    "for i, row in df_test.iterrows():\n",
    "    df_test.at[i, 'input'] = \" <cls> \" + str(row[1]) + \" <sep> \" + str(row[2]) + \" <cls> \"\n",
    "    if(i % 100000) == 0 and i:\n",
    "        print(\"Completed: %s\" %(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4d2a054-b4fc-4433-aeba-55366d052809",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True, sep_token = '<sep>', cls_token = '<cls>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8690db70-1c3d-4336-ab0d-5ebd39a8e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_train = df_train['input'].tolist()\n",
    "labels_train = df_train['score'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eb1bc74-d77c-4794-814c-074bc2a24039",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dev = df_dev['input'].tolist()\n",
    "labels_dev = df_dev['score'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d48811e-a5b2-4c99-8dee-151dfe9b55d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_test = df_test['input'].tolist()\n",
    "labels_test = df_test['score'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2020f858-3a16-44d0-8772-63353faf41dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts_train = [tokenizer.tokenize(inp) for inp in inp_train]\n",
    "input_ids_train = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "785e3252-43cb-4d88-a20e-2015761344b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31bcad0c-9fef-4fd9-a541-25701e888628",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks_train = []\n",
    "\n",
    "for seq in input_ids_train:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks_train.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "279baa8f-bb3c-4aa6-8226-725bef119743",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(input_ids_train)\n",
    "train_labels = torch.tensor(labels_train)\n",
    "train_masks = torch.tensor(attention_masks_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3bd93c-3bd3-4ec9-b6b6-527265de653d",
   "metadata": {},
   "source": [
    "##### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc850807-2fd6-4b72-b3e2-a17bb724143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11485b37-d1b6-4b2d-beac-11fe55a9c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts_dev = [tokenizer.tokenize(inp) for inp in inp_dev]\n",
    "input_ids_dev = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41924cd6-50b2-4dc7-9b28-93962f141f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_dev = pad_sequences(input_ids_dev, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "508db3fc-8ae3-4e2a-9425-248102efaec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks_dev = []\n",
    "\n",
    "for seq in input_ids_dev:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks_dev.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd4db02d-0b76-46f2-866f-cf2f0158f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_inputs = torch.tensor(input_ids_dev)\n",
    "dev_labels = torch.tensor(labels_dev)\n",
    "dev_masks = torch.tensor(attention_masks_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c1b046-a059-4a9f-b985-19bd19147d5a",
   "metadata": {},
   "source": [
    "##### Dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6ae6187-bfbd-4cc0-bbf5-06a667f51b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = TensorDataset(dev_inputs, dev_masks, dev_labels)\n",
    "dev_sampler = RandomSampler(dev_data)\n",
    "dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2ec5a66-6601-46c3-b097-de78cee72cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts_test = [tokenizer.tokenize(inp) for inp in inp_test]\n",
    "input_ids_test = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "146da8e1-d338-4378-a53e-bc28090d88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10991566-88ab-440a-8a6c-97952af090d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks_test = []\n",
    "\n",
    "for seq in input_ids_test:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks_test.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75dd83e6-81f9-49c4-acf8-cfe3361df7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = torch.tensor(input_ids_test)\n",
    "test_labels = torch.tensor(labels_test)\n",
    "test_masks = torch.tensor(attention_masks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "054db3ec-5ae6-46fb-91b4-261702402f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "#test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140485b-9282-4162-9aef-12472efd4198",
   "metadata": {},
   "source": [
    "## Models and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b24176aa-41fa-4605-97a6-8b03de859f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): XLN_Reg(\n",
       "    (transformer): XLNetModel(\n",
       "      (word_embedding): Embedding(32000, 768)\n",
       "      (layer): ModuleList(\n",
       "        (0): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (6): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (7): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (8): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (9): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (10): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (11): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output_linear): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class XLN_Reg(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(XLN_Reg, self).__init__()\n",
    "        self.transformer = XLNetModel.from_pretrained(\"xlnet-base-cased\")\n",
    "        self.output_linear = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, input_ids, input_mask):\n",
    "        transformer_out = self.transformer(input_ids, token_type_ids=None, attention_mask=input_mask)\n",
    "        out = self.output_linear(transformer_out[0][:, 0])\n",
    "        return out\n",
    "\n",
    "model = XLN_Reg()\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3486d63-c25e-4f3d-b9eb-14bda23ecd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Model Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60ec3bde-66a1-42f7-89f0-02f79ecd7459",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1932618360.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [34]\u001b[1;36m\u001b[0m\n\u001b[1;33m    'weight_decay_rate': 0c.0}\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0c.0}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c2893e-4c36-4b11-952e-e35070c4bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b09f18-a5ff-481f-ab90-b9a297c439b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Optimizerlr: %s\\tLR1_ML: %s\" %(optimizer.param_groups[0]['lr'], lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc4980-3fca-4acc-bc43-47e373374b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = preds.flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    labels_flat = labels_flat.cpu().detach().numpy() \n",
    "    return np.sum(np.abs(pred_flat - labels_flat)), pred_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e966d7b4-dc75-41f3-b266-324fc21c8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(i):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_predicted_label = np.array([])\n",
    "    total_actual_label = np.array([])\n",
    "    train_len = 0\n",
    "    f_acc = 0\n",
    "\n",
    "    ## adaptive lr\n",
    "    optimizer.param_groups[0]['lr'] *= (0.1)**(1/40.)\n",
    "\n",
    "    logging.info(\"LR: %s\\tEpoch: %s\\t\" %(optimizer.param_groups[0]['lr'], i)) \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        if b_labels.size(0) == 1:\n",
    "            continue\n",
    "        optimizer.zero_grad()v\n",
    "        outputs = model(b_input_ids, b_input_mask)\n",
    "\n",
    "        pred = outputs.detach().cpu().numpy()\n",
    "        batch_f_acc, pred_flat = flat_accuracy(pred, b_labels)\n",
    "        f_acc += batch_f_acc\n",
    "        loss = loss_fn(outputs.squeeze(-1), b_labels)\n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        labels_flat = b_labels.flatten().cpu().detach().numpy()\n",
    "        total_actual_label = np.concatenate((total_actual_label, labels_flat))\n",
    "        total_predicted_label = np.concatenate((total_predicted_label, pred_flat))\n",
    "\n",
    "        #  print(total_actual_label.shape, total_predicted_label.shape)\n",
    "        total_loss += outputs[0].sum()\n",
    "        train_len += b_input_ids.size(0)\n",
    "\n",
    "        # if step%100 == 0 and step:\n",
    "        # precision, recall, f1_measure, _ = precision_recall_fscore_support(total_actual_label, total_predicted_label, average='macro')\n",
    "        # logging.info(\"Train: %5.1f\\tEpoch: %d\\tIter: %d\\tLoss: %5.5f\\tAcc= %5.3f\\tPrecision= %5.3f\\tRecall= %5.3f\\tF1_score= %5.3f\" %(train_len*100.0/train_inputs.size(0), i, step,total_loss/train_len, f_acc*100.0/train_len, precision*100., recall*100., f1_measure*100.))\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        p = 100\n",
    "        path = save_model_path + '/e_' + str(i) + \"_\" + str(p) + \".ckpt\"\n",
    "        torch.save(model.module.state_dict(), path)\n",
    "    else:\n",
    "        p = 00\n",
    "        path = save_model_path + '/e_' + str(i) + \"_\" + str(p) + \".ckpt\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "    # precision, recall, f1_measure, _ = precision_recall_fscore_support(total_actual_label, total_predicted_label, average='macro')\n",
    "    # logging.info(\"Train: %5.1f\\tEpoch: %d\\tIter: %d\\tLoss: %5.5f\\tAcc= %5.3f\\tPrecision= %5.3f\\tRecall= %5.3f\\tF1_score= %5.3f\" % (train_len*100.0/train_inputs.size(0), i, step,total_loss/train_len, f_acc*100.0/train_len,precision*100., recall*100., f1_measure*100.))\n",
    "    return total_loss/train_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb970d-b4db-4547-814c-0235a8b229e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev(i):\n",
    "    model.eval()\n",
    "    val_len = 0\n",
    "    total_loss = 0\n",
    "    total_predicted_label = np.array([])\n",
    "    total_actual_label = np.array([])\n",
    "    f_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(dev_dataloader):\n",
    "            batch = tuple(t.cuda() for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            if b_labels.size(0) == 1:\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(b_input_ids, b_input_mask)\n",
    "            pred = outputs.detach().cpu().numpy()\n",
    "            batch_f_acc, pred_flat = flat_accuracy(pred, b_labels)\n",
    "            f_acc += batch_f_acc\n",
    "\n",
    "            labels_flat = b_labels.flatten().cpu().detach().numpy()\n",
    "            total_actual_label = np.concatenate((total_actual_label, labels_flat))\n",
    "            total_predicted_label = np.concatenate((total_predicted_label, pred_flat))\n",
    "\n",
    "            val_len += b_input_ids.size(0)\n",
    "            total_loss += loss_fn(outputs.squeeze(-1), b_labels).sum()\n",
    "\n",
    "            # if step%100 == 0 and step:\n",
    "            #     precision, recall, f1_measure, _ = precision_recall_fscore_support(total_actual_label, total_predicted_label, average='macro')\n",
    "            #     logging.info(\"Eval: %5.1f\\tEpoch: %d\\tIter: %d\\tLoss: %5.5f\\tAcc= %5.3f\\tPrecision= %5.3f\\tRecall= %5.3f\\tF1_score= %5.3f\" % (val_len*100.0/dev_inputs.size(0), i, step,total_loss/val_len, f_acc*100.0/val_len,precision*100., recall*100., f1_measure*100.))\n",
    "\n",
    "        # precision, recall, f1_measure, _ = precision_recall_fscore_support(total_actual_label, total_predicted_label, average='macro')\n",
    "        # logging.info(\"Validation: %5.1f\\tEpoch: %d\\tIter: %d\\tLoss: %5.5f\\tAcc= %5.3f\\tPrecision= %5.3f\\tRecall= %5.3f\\tF1_score= %5.3f\" % (val_len*100.0/dev_inputs.size(0), i, step,total_loss/val_len, f_acc*100.0/val_len,precision*100., recall*100., f1_measure*100.))\n",
    "    return total_loss/val_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b4ae5c-0444-4418-b1e3-bacdd76294ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(i):\n",
    "    model.eval()\n",
    "    val_len = 0\n",
    "    total_loss = 0\n",
    "    total_predicted_label = np.array([])\n",
    "    total_actual_label = np.array([])\n",
    "    f_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(test_dataloader):\n",
    "            #batch = tuple(t.cuda() for t in batch)\n",
    "            batch = tuple(t.cuda() for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            if b_labels.size(0) == 1:\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(b_input_ids, b_input_mask)\n",
    "            pred = outputs.detach().cpu().numpy()\n",
    "            batch_f_acc, pred_flat = flat_accuracy(pred, b_labels)\n",
    "            f_acc += batch_f_acc\n",
    "\n",
    "            labels_flat = b_labels.flatten().cpu().detach().numpy()\n",
    "            total_actual_label = np.concatenate((total_actual_label, labels_flat))\n",
    "            total_predicted_label = np.concatenate((total_predicted_label, pred_flat))\n",
    "\n",
    "            val_len += b_input_ids.size(0)\n",
    "            total_loss += loss_fn(outputs.squeeze(-1), b_labels).sum()\n",
    "\n",
    "            # if step%100 == 0 and step:\n",
    "            # precision, recall, f1_measure, _ = precision_recall_fscore_support(total_actual_label, total_predicted_label, average='macro')\n",
    "            # logging.info(\"Eval: %5.1f\\tEpoch: %d\\tIter: %d\\tLoss: %5.5f\\tAcc= %5.3f\\tPrecision= %5.3f\\tRecall= %5.3f\\tF1_score= %5.3f\" % (val_len*100.0/test_inputs.size(0), i, step, total_loss/val_len, f_acc*100.0/val_len, precision*100., recall*100., f1_measure*100.))\n",
    "\n",
    "        # precision, recall, f1_measure, _ = precision_recall_fscore_support(total_actual_label, total_predicted_label, average='macro')\n",
    "        # logging.info(\"Test: %5.1f\\tEpoch: %d\\tIter: %d\\tLoss: %5.5f\\tAcc= %5.3f\\tPrecision= %5.3f\\tRecall= %5.3f\\tF1_score= %5.3f\" % (val_len*100.0/test_inputs.size(0), i, step, total_loss/val_len, f_acc*100.0/val_len, precision*100., recall*100., f1_measure*100.))\n",
    "        return total_actual_label, total_predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d6a81-db39-49ee-92a5-032ba3c049ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson(vector1, vector2):\n",
    "    n = len(vector1)\n",
    "    sum1 = sum(float(vector1[i]) for i in range(n))\n",
    "    sum2 = sum(float(vector2[i]) for i in range(n))\n",
    "    sum1_pow = sum([pow(v, 2.0) for v in vector1])\n",
    "    sum2_pow = sum([pow(v, 2.0) for v in vector2])\n",
    "    p_sum = sum([vector1[i] * vector2[i] for i in range(n)])\n",
    "    num = p_sum - (sum1 * sum2 / n)\n",
    "    den = math.sqrt((sum1_pow - pow(sum1, 2.0) / n) * (sum2_pow - pow(sum2, 2) / n))\n",
    "    if den == 0:\n",
    "        return 0.0\n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0272e7-017e-42da-882e-7d0e1ca4b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89b309-9347-4d2c-85c1-60d412aa6beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "for i in range(num_epochs):\n",
    "    train_loss.append(train(i))\n",
    "    val_loss.append(dev(i))\n",
    "\n",
    "\n",
    "    actual, predicted = test(i)\n",
    "    pear = pearson(actual.tolist(), predicted.tolist())\n",
    "\n",
    "\n",
    "    pkl.dump(actual, open('actual', 'wb'))\n",
    "    pkl.dump(predicted, open('predicted', 'wb'))\n",
    "\n",
    "    pkl.dump(val_loss, open('val_loss.pkl', 'wb'))\n",
    "    pkl.dump(train_loss, open('train_loss.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161dedcc-d4dd-45cb-86d0-c9a48d75f358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fde699-31d8-486d-af44-c5c560243e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815f1d4b-d7ef-49e5-bdcd-6592ac676530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724ef5ab-d705-49e0-ba27-0bdd4358ec85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
